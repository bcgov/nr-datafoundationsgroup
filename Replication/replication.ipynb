{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70f1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.pool\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84144cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508e7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_batch\n",
    "import configparser\n",
    "import time\n",
    "import json  # Import the json module\n",
    "import concurrent.futures\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da5ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/ODS/rrs_extract.json', 'r') as json_file:\n",
    "    config_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a257d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr_schema='app_rrs1'\n",
    "app_name='FTA'\n",
    "\n",
    "#source_schema = config_data['init']['source_schema']\n",
    "#target_schema = config_data['init']['target_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8338eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'{source_schema}::{target_schema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2545c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Load the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('C:/ODS/config.ini')\n",
    "\n",
    "# Retrieve Oracle database configuration\n",
    "oracle_username = config['oracle']['username']\n",
    "oracle_password = config['oracle']['password']\n",
    "oracle_host = config['oracle']['host']\n",
    "oracle_port = config['oracle']['port']\n",
    "oracle_database = config['oracle']['database']\n",
    "\n",
    "# Retrieve Postgres database configuration\n",
    "postgres_username = config['postgres']['username']\n",
    "postgres_password = config['postgres']['password']\n",
    "postgres_host = config['postgres']['host']\n",
    "postgres_port = config['postgres']['port']\n",
    "postgres_database = config['postgres']['database']\n",
    "\n",
    "#Concurrent tasks - number of tables to be replicated in parallel\n",
    "concurrent_tasks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40fae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrkdb03.bcgov 1521 rrsprd1.nrs.bcgov vreddy Dqpy$851\n",
      "Oracle Pool Successful\n"
     ]
    }
   ],
   "source": [
    "# Set up Oracle connection pool\n",
    "dsn = cx_Oracle.makedsn(host=oracle_host, port=oracle_port, service_name=oracle_database)\n",
    "OrcPool = cx_Oracle.SessionPool(user=oracle_username, password=oracle_password, dsn=dsn, min=concurrent_tasks,\n",
    "                             max=concurrent_tasks, increment=1, encoding=\"UTF-8\")\n",
    "print(oracle_host, oracle_port, oracle_database, oracle_username, oracle_password)\n",
    "print('Oracle Pool Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5955de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postgres Connection Successful\n"
     ]
    }
   ],
   "source": [
    "PgresPool = psycopg2.pool.ThreadedConnectionPool(\n",
    "    minconn = concurrent_tasks, maxconn = concurrent_tasks,host=postgres_host, port=postgres_port, dbname=postgres_database, user=postgres_username, password=postgres_password\n",
    ")\n",
    "print('Postgres Connection Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7fa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_tables(mstr_schema,app_name):\n",
    "  postgres_connection  = PgresPool.getconn()  \n",
    "  postgres_cursor = postgres_connection.cursor()\n",
    "  list_sql = f\"\"\"\n",
    "  SELECT application_name,source_schema_name,source_table_name,target_schema_name,target_table_name,truncate_flag,cdc_flag,full_inc_flag,cdc_column,replication_order\n",
    "  from {mstr_schema}.cdc_master_table_list c\n",
    "  where  active_ind = 'Y' and application_name='{app_name}'\n",
    "  order by replication_order, source_table_name\n",
    "  \"\"\"\n",
    "  with postgres_connection.cursor() as curs:\n",
    "            curs.execute(list_sql)\n",
    "            rows = curs.fetchall()\n",
    "  postgres_connection.commit()\n",
    "  postgres_cursor.close()\n",
    "  PgresPool.putconn(postgres_connection)\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c731cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from Oracle\n",
    "def extract_from_oracle(table_name,source_schema):\n",
    "    # Acquire a connection from the pool\n",
    "    oracle_connection = OrcPool.acquire()\n",
    "    oracle_cursor = oracle_connection.cursor()    \n",
    "    try:\n",
    "        # Use placeholders in the query and bind the table name as a parameter\n",
    "        sql_query = f'SELECT * FROM {source_schema}.{table_name}'\n",
    "        print(sql_query)\n",
    "        oracle_cursor.execute(sql_query)\n",
    "        rows = oracle_cursor.fetchall()\n",
    "        OrcPool.release(oracle_connection)\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from Oracle: {str(e)}\")\n",
    "        OrcPool.release(oracle_connection)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729fdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data into PostgreSQL using execute_batch\n",
    "def load_into_postgres(table_name, data,target_schema):\n",
    "    postgres_connection = PgresPool.getconn()\n",
    "    postgres_cursor = postgres_connection.cursor()\n",
    "    try:\n",
    "        # Delete existing data in the target table\n",
    "        delete_query = f'TRUNCATE TABLE {target_schema}.{table_name}'\n",
    "        postgres_cursor.execute(delete_query)\n",
    "\n",
    "        # Build the INSERT query with placeholders\n",
    "        insert_query = f'INSERT INTO {target_schema}.{table_name} VALUES ({\", \".join([\"%s\"] * len(data[0]))})'\n",
    "        #insert_query = f'INSERT INTO {target_schema}.{table_name} VALUES %s'\n",
    "\n",
    "        # Use execute_batch for efficient batch insert\n",
    "        with postgres_connection.cursor() as cursor:\n",
    "            # Prepare the data as a list of tuples\n",
    "            data_to_insert = [(tuple(row)) for row in data]\n",
    "            execute_batch(cursor, insert_query, data_to_insert)\n",
    "            postgres_connection.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data into PostgreSQL: {str(e)}\")\n",
    "    finally:\n",
    "        # Return the connection to the pool\n",
    "        if postgres_connection:\n",
    "            postgres_cursor.close()\n",
    "            PgresPool.putconn(postgres_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efb979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_src_tgt(table_name,source_schema,target_schema):\n",
    "        # Extract data from Oracle\n",
    "        print(f'Source: Thread {table_name} started at ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        oracle_data = extract_from_oracle(table_name,source_schema)  # Ensure table name is in uppercase\n",
    "        print(f'Source: Extraction for {table_name} completed at ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        if oracle_data:\n",
    "            # Load data into PostgreSQL\n",
    "            load_into_postgres(table_name, oracle_data, target_schema)\n",
    "            print(f\"Target: Data loaded into table: {table_name}\")\n",
    "            print(f'Target: Thread {table_name} ended at ' + datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e055884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FTA', 'the', 'CLIENT_LOCATION', 'fta_replication', 'CLIENT_LOCATION', 'Y', None, None, 'UPDATE_DATE', 1), ('FTA', 'the', 'CUT_BLOCK', 'fta_replication', 'CUT_BLOCK', 'Y', None, None, 'UPDATE_DATE', 1), ('FTA', 'the', 'ORG_UNIT', 'fta_replication', 'ORG_UNIT', 'Y', '', '', 'UPDATE_DATE', 1), ('FTA', 'the', 'TENURE_APPLICATION_PURP_CODE', 'fta_replication', 'TENURE_APPLICATION_PURP_CODE', 'Y', None, None, 'UPDATE_DATE', 1), ('FTA', 'the', 'AAC_ALLOCATION_AMOUNT', 'fta_replication', 'AAC_ALLOCATION_AMOUNT', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'FILE_CLIENT_TYPE_CODE', 'fta_replication', 'FILE_CLIENT_TYPE_CODE', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'FILE_SOURCE_CODE', 'fta_replication', 'FILE_SOURCE_CODE', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'FILE_STATUS_CODE', 'fta_replication', 'FILE_STATUS_CODE', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'FOREST_CLIENT', 'fta_replication', 'FOREST_CLIENT', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'TENURE_FILE_STATUS_CODE', 'fta_replication', 'TENURE_FILE_STATUS_CODE', 'Y', None, None, 'UPDATE_DATE', 2), ('FTA', 'the', 'TENURE_STATUS_CODE', 'fta_replication', 'TENURE_STATUS_CODE', 'Y', None, None, 'UPDATE_DATE', 2)]\n",
      "tables to extract are [('CLIENT_LOCATION', 'the', 'fta_replication'), ('CUT_BLOCK', 'the', 'fta_replication'), ('ORG_UNIT', 'the', 'fta_replication'), ('TENURE_APPLICATION_PURP_CODE', 'the', 'fta_replication'), ('AAC_ALLOCATION_AMOUNT', 'the', 'fta_replication'), ('FILE_CLIENT_TYPE_CODE', 'the', 'fta_replication'), ('FILE_SOURCE_CODE', 'the', 'fta_replication'), ('FILE_STATUS_CODE', 'the', 'fta_replication'), ('FOREST_CLIENT', 'the', 'fta_replication'), ('TENURE_FILE_STATUS_CODE', 'the', 'fta_replication'), ('TENURE_STATUS_CODE', 'the', 'fta_replication')]\n",
      "No of concurrent tasks:5\n",
      "Source: Thread CLIENT_LOCATION started at 17:06:50\n",
      "Source: Thread CUT_BLOCK started at 17:06:50\n",
      "Source: Thread ORG_UNIT started at 17:06:50\n",
      "SELECT * FROM the.CLIENT_LOCATION\n",
      "SELECT * FROM the.ORG_UNIT\n",
      "SELECT * FROM the.CUT_BLOCK\n",
      "Source: Thread TENURE_APPLICATION_PURP_CODE started at 17:06:50\n",
      "SELECT * FROM the.TENURE_APPLICATION_PURP_CODE\n",
      "Source: Thread AAC_ALLOCATION_AMOUNT started at 17:06:50\n",
      "SELECT * FROM the.AAC_ALLOCATION_AMOUNT\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for ORG_UNIT completed at 17:06:50\n",
      "Source: Thread FILE_CLIENT_TYPE_CODE started at 17:06:50\n",
      "Source: Extraction for CLIENT_LOCATION completed at 17:06:50\n",
      "Source: Thread FILE_SOURCE_CODE started at 17:06:50\n",
      "SELECT * FROM the.FILE_SOURCE_CODE\n",
      "Source: Extraction for TENURE_APPLICATION_PURP_CODE completed at 17:06:50\n",
      "Source: Thread FILE_STATUS_CODE started at 17:06:50\n",
      "Source: Extraction for AAC_ALLOCATION_AMOUNT completed at 17:06:50\n",
      "Source: Thread FOREST_CLIENT started at 17:06:50\n",
      "SELECT * FROM the.FILE_CLIENT_TYPE_CODE\n",
      "SELECT * FROM the.FOREST_CLIENT\n",
      "SELECT * FROM the.FILE_STATUS_CODE\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for FILE_SOURCE_CODE completed at 17:06:50\n",
      "Source: Thread TENURE_FILE_STATUS_CODE started at 17:06:50\n",
      "SELECT * FROM the.TENURE_FILE_STATUS_CODE\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for FILE_CLIENT_TYPE_CODE completed at 17:06:50\n",
      "Source: Thread TENURE_STATUS_CODE started at 17:06:50\n",
      "SELECT * FROM the.TENURE_STATUS_CODE\n",
      "Source: Extraction for FILE_STATUS_CODE completed at 17:06:50\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for FOREST_CLIENT completed at 17:06:50\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for TENURE_FILE_STATUS_CODE completed at 17:06:50\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for TENURE_STATUS_CODE completed at 17:06:50\n",
      "Error extracting data from Oracle: ORA-00942: table or view does not exist\n",
      "Source: Extraction for CUT_BLOCK completed at 17:06:51\n",
      "ETL process completed successfully.\n",
      "The time of execution of the program is: 3.3949990272521973 secs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Main ETL process\n",
    "    active_tables_rows =get_active_tables(target_schema) \n",
    "    print(active_tables_rows)\n",
    "    tables_to_extract = [row[2] for row in active_tables_rows]\n",
    "    print(f\"tables to extract are {tables_to_extract}\")\n",
    "    print(f'No of concurrent tasks:{concurrent_tasks}')\n",
    "    # Using ThreadPoolExecutor to run tasks concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_tasks) as executor:\n",
    "        # Submit tasks to the executor\n",
    "        future_to_table = {executor.submit(load_data_from_src_tgt, table): table for table in tables_to_extract}\n",
    "        \n",
    "        # Wait for all tasks to complete\n",
    "        concurrent.futures.wait(future_to_table)\n",
    "        \n",
    "        # Print results\n",
    "        for future in future_to_table:\n",
    "            table_name = future_to_table[future]\n",
    "            try:\n",
    "                # Get the result of the task, if any\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                # Handle exceptions that occurred during the task\n",
    "                print(f\"Error replicating {table_name}: {e}\")\n",
    "    \n",
    "    # record end time\n",
    "    end = time.time()\n",
    "    OrcPool.close()\n",
    "    PgresPool.closeall()\n",
    "    \n",
    "    print(\"ETL process completed successfully.\")\n",
    "    print(\"The time of execution of the program is:\", (end - start) , \"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079af2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
